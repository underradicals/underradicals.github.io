import{_ as e,c as t,o as n,ae as i}from"./chunks/framework.U1Gow_7P.js";const p=JSON.parse('{"title":"Data Engineering","description":"","frontmatter":{"layout":"doc"},"headers":[],"relativePath":"data_engineering/index.md","filePath":"data_engineering/index.md"}'),s={name:"data_engineering/index.md"};function o(r,a,d,l,c,u){return n(),t("div",null,a[0]||(a[0]=[i('<h1 id="data-engineering" tabindex="-1">Data Engineering <a class="header-anchor" href="#data-engineering" aria-label="Permalink to &quot;Data Engineering&quot;">​</a></h1><p>To drive innovations and improve business outcomes, organizations of all types and sizes are asking important questions such as:</p><p>How can we offer hyper-personalized experiences to our customers? How can we empower our business users to make data-driven decisions? And, of course, where can we innovate, improve operations, and optimize costs? To answer these questions, organizations need to foster a data-driven culture, democratize access to data and insights, and leverage innovative technologies such as data analytics, machine learning, and generative AI applications.</p><p>But there are challenges. Many organizations experience data management issues such as data and processing silos, excessive data movement, and data duplication across business units.</p><p>That’s where you come in.</p><p>As a data engineer, you play a crucial role in transforming raw data into valuable insights for organizations. You design, develop, and maintain data architectures and extract, transform, load (ETL) pipelines that data analysts, data scientists, and other data consumers can use to effectively access and analyze data.</p><p>Essentially, the role of the data engineer can be summed up as getting data from sources, making it useful, and then serving it to stakeholders.</p><div class="tip custom-block"><p class="custom-block-title">Responsibility of DE &amp; DA</p><p>The data engineer builds the system that delivers usable data to the data analyst, who analyzes the data to gain business insights.</p></div><h2 id="what-are-the-key-functions-of-the-data-engineer" tabindex="-1">What are the key functions of the data engineer? <a class="header-anchor" href="#what-are-the-key-functions-of-the-data-engineer" aria-label="Permalink to &quot;What are the key functions of the data engineer?&quot;">​</a></h2><p>The following is a list of some important data engineer functions. In your organization, you might perform all these functions, or you might share them with other specialists.</p><h4 id="build-and-manage-data-infrastructure-and-platforms" tabindex="-1">Build and manage data infrastructure and platforms <a class="header-anchor" href="#build-and-manage-data-infrastructure-and-platforms" aria-label="Permalink to &quot;Build and manage data infrastructure and platforms&quot;">​</a></h4><p>This includes setting up databases, data lakes, and data warehouses on AWS services like Amazon Simple Storage Service (Amazon S3), AWS Glue, Amazon Redshift, among others.</p><h4 id="ingest-data-from-various-sources" tabindex="-1">Ingest data from various sources <a class="header-anchor" href="#ingest-data-from-various-sources" aria-label="Permalink to &quot;Ingest data from various sources&quot;">​</a></h4><p>You can use tools like AWS Glue jobs or AWS Lambda functions to ingest data from databases, applications, files, and streaming devices into the centralized data platforms.</p><h4 id="prepare-the-ingested-data-for-analytics" tabindex="-1">Prepare the ingested data for analytics <a class="header-anchor" href="#prepare-the-ingested-data-for-analytics" aria-label="Permalink to &quot;Prepare the ingested data for analytics&quot;">​</a></h4><p>Use technologies like AWS Glue, Apache Spark, or Amazon EMR to prepare data by cleaning, transforming, and enriching it.</p><h4 id="catalog-and-document-curated-datasets" tabindex="-1">Catalog and document curated datasets <a class="header-anchor" href="#catalog-and-document-curated-datasets" aria-label="Permalink to &quot;Catalog and document curated datasets&quot;">​</a></h4><p>Use AWS Glue crawlers to determine the format and schema, group data into tables, and write metadata to the AWS Glue Data Catalog. Use metadata tagging in Data Catalog for data governance and discoverability.</p><h4 id="automate-regular-data-workflows-and-pipelines" tabindex="-1">Automate regular data workflows and pipelines <a class="header-anchor" href="#automate-regular-data-workflows-and-pipelines" aria-label="Permalink to &quot;Automate regular data workflows and pipelines&quot;">​</a></h4><p>Simplify and accelerate data processing using services like AWS Glue workflows, AWS Lambda, or AWS Step Functions.</p><div class="tip custom-block"><p class="custom-block-title">Key Functions of the DE</p><ol><li>They build and manage data infrastructure platforms.</li><li>They catalog and document datasets.</li><li>They ensure security and compliance.</li></ol></div><h4 id="ensure-data-quality-security-and-compliance" tabindex="-1">Ensure data quality, security, and compliance <a class="header-anchor" href="#ensure-data-quality-security-and-compliance" aria-label="Permalink to &quot;Ensure data quality, security, and compliance&quot;">​</a></h4><p>Create access controls, establish authorization policies, and build monitoring processes. Use Amazon DataZone or AWS Lake Formation to manage and govern access to data using fine-grained controls. These controls help ensure access with the right level of privileges and context.</p><h3 id="as-a-de-who-will-help-you-solve-problems" tabindex="-1">As a DE who will help you solve problems <a class="header-anchor" href="#as-a-de-who-will-help-you-solve-problems" aria-label="Permalink to &quot;As a DE who will help you solve problems&quot;">​</a></h3><p>Building, running, and maintaining a data analytics system is a highly collaborative endeavor. You will work with people in varied roles, including executive, managerial, and technical. The following table identifies the responsibilities and areas of interest for the various personas that work with a data analytics system.</p><table tabindex="0"><thead><tr><th>Personas</th><th>Responsibility</th><th>Areas of interest</th></tr></thead><tbody><tr><td>Chief data officer (CDO)</td><td>Builds a culture of using data to solve problems and accelerate innovation</td><td>Data quality, data governance, data and AI strategy, evangelizing the value of data to the business</td></tr><tr><td>Data architect</td><td>Architects technical solutions to meet business needs; solves complex data challenges to help the CDO deliver on their vision</td><td>Data pipeline, data processing, data integration, data governance, data catalogs</td></tr><tr><td>Data engineer</td><td>Delivers usable, accurate datasets to the organization in a secure and high-performing manner</td><td>Tools for building data pipelines, ease of use, configuration, and maintenance</td></tr><tr><td>Data security officer</td><td>Ensures data security, privacy, and governance are strictly defined and adhered to</td><td>Information security, data privacy compliance, protecting PII, fine-grained access controls, data masking</td></tr><tr><td>Data scientist</td><td>Constructs means for extracting business-focused insight from data to support better decisions</td><td>Tools for data manipulation, insight beyond visualization, and tools to build ML pipelines</td></tr><tr><td>Data analyst</td><td>Reacts to market conditions in real time; finds data and performs analytics quickly and easily</td><td>Querying data, performing analysis, creating business insights, producing reports and visualizations</td></tr></tbody></table>',26)]))}const g=e(s,[["render",o]]);export{p as __pageData,g as default};
